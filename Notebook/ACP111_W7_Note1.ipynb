{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4CqEDsbYXFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd34ed7-13da-42da-b38b-c025c80cf7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Scrapy-2.6.1 Twisted-22.2.0 constantly-15.1.0 cryptography-36.0.1 cssselect-1.1.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.4.0 itemloaders-1.0.4 jmespath-0.10.0 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.0.0 queuelib-1.6.2 requests-file-1.5.1 service-identity-21.1.0 tldextract-3.2.0 w3lib-1.22.0 zope.interface-5.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install Scrapy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "class ArticleSpider(scrapy.Spider):\n",
        "    name='cna_news'\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = ['https://www.cna.com.tw/']\n",
        "        return [scrapy.Request(url=url, callback=self.parse) for url in urls]\n",
        "\n",
        "    def parse(self, response):\n",
        "        bs = BeautifulSoup(response.body, 'html.parser')\n",
        "        titleList = bs.findAll('div', {'class':'title'})\n",
        "        for title in titleList:\n",
        "            print(title.get_text())"
      ],
      "metadata": {
        "id": "8MiGHi6TYbjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from twisted.internet import reactor\n",
        "from scrapy.crawler import CrawlerRunner\n",
        "crawler = CrawlerRunner()\n",
        "d = crawler.crawl(ArticleSpider)\n",
        "d.addBoth(lambda _: reactor.stop())\n",
        "reactor.run()"
      ],
      "metadata": {
        "id": "jM2C3vtobXol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172e7686-67d8-4fd1-a908-5be88edb7222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "長程輪美國擱淺 長榮：正在確認船體是否受損\n",
            "NASA：國際太空站正常運作 不受俄烏衝突影響\n",
            "城市科大校友創業開早午餐店 用大數據開發菜單\n",
            "公視片庫資料遭廠商誤刪  8萬筆遺失\n",
            "長榮貨櫃輪卡美國吉布森島外海未影響主要航道 數艘拖船馳援[影]\n",
            "幻象2000飛官黃重凱獲救 情況良好最快16日出院\n",
            "中國本土病例暴增逾5000例 吉林是重災區\n",
            "日本丹頂鶴復育有成 保育團體缺錢追蹤募資求助\n",
            "幻象戰機失事原因 邱國正：不是因為缺件造成\n",
            "陽明高股利遭逢台股賣壓 貨櫃三雄開高壓回\n"
          ]
        }
      ]
    }
  ]
}